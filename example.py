"""
RAPTORä½¿ç”¨ä¾‹
ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€RAPTORã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ç¤ºã—ã¾ã™ã€‚
"""

from langchain_ollama import ChatOllama, OllamaEmbeddings
from raptor import RAPTORRetriever

def main():
    print("ğŸš€ RAPTOR Example - Starting...")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    print("\nğŸ“¦ Initializing models...")
    llm = ChatOllama(
        model="granite-code:8b",
        base_url="http://localhost:11434",
        temperature=0
    )
    
    embeddings_model = OllamaEmbeddings(
        model="mxbai-embed-large",
        base_url="http://localhost:11434"
    )
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: RAPTORãƒ¬ãƒˆãƒªãƒ¼ãƒãƒ¼ã®ä½œæˆ
    print("ğŸŒ³ Creating RAPTOR retriever...")
    raptor = RAPTORRetriever(
        embeddings_model=embeddings_model,
        llm=llm,
        max_clusters=3,   # å„ãƒ¬ãƒ™ãƒ«ã§æœ€å¤§3ã‚¯ãƒ©ã‚¹ã‚¿
        max_depth=2,      # æœ€å¤§2éšå±¤
        chunk_size=1000,  # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
        chunk_overlap=200 # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
    )
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
    print("\nğŸ“š Indexing document...")
    print("Note: ../test.txt ã‚’ä½¿ç”¨ã—ã¾ã™")
    print("ç‹¬è‡ªã®æ–‡æ›¸ã‚’ä½¿ã†å ´åˆã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„")
    
    try:
        raptor.index("../test.txt")
    except FileNotFoundError:
        print("âŒ Error: ../test.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ç‹¬è‡ªã®.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã¦ã€ãƒ‘ã‚¹ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„")
        return
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: æ¤œç´¢å®Ÿè¡Œ
    print("\nğŸ” Performing searches...")
    
    # ã‚¯ã‚¨ãƒª1
    query1 = "philosophy"
    print(f"\n{'='*60}")
    print(f"Query 1: '{query1}'")
    print('='*60)
    results1 = raptor.retrieve(query1, top_k=3)
    
    print(f"\nğŸ“„ Top {len(results1)} results:")
    for i, doc in enumerate(results1, 1):
        print(f"\n--- Result {i} ---")
        print(f"Preview: {doc.page_content[:250]}...")
        if doc.metadata:
            print(f"Metadata: {doc.metadata}")
    
    # ã‚¯ã‚¨ãƒª2
    query2 = "ancient history"
    print(f"\n{'='*60}")
    print(f"Query 2: '{query2}'")
    print('='*60)
    results2 = raptor.retrieve(query2, top_k=3)
    
    print(f"\nğŸ“„ Top {len(results2)} results:")
    for i, doc in enumerate(results2, 1):
        print(f"\n--- Result {i} ---")
        print(f"Preview: {doc.page_content[:250]}...")
        if doc.metadata:
            print(f"Metadata: {doc.metadata}")
    
    # çµ±è¨ˆæƒ…å ±
    print(f"\n{'='*60}")
    print("ğŸ“Š Statistics")
    print('='*60)
    print(f"Total queries executed: 2")
    print(f"Results per query: 3")
    print(f"Tree depth: 2")
    print(f"Max clusters per level: 3")
    
    print("\nâœ… Example completed successfully!")
    print("\nğŸ’¡ Next steps:")
    print("   1. Try different queries")
    print("   2. Adjust max_clusters and max_depth")
    print("   3. Use your own documents")
    print("   4. Customize the summarization prompt")

if __name__ == "__main__":
    main()
