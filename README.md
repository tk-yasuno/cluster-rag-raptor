# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval

ğŸŒ³ éšå±¤çš„æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®å®Œå…¨ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3+-green.svg)](https://python.langchain.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ æ¦‚è¦

RAPTORã¯ã€å¤§è¦æ¨¡æ–‡æ›¸ã‹ã‚‰åŠ¹ç‡çš„ã«æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®é©æ–°çš„ãªRAGï¼ˆRetrieval-Augmented Generationï¼‰æ‰‹æ³•ã§ã™ã€‚å¾“æ¥ã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ã¯ç•°ãªã‚Šã€æ–‡æ›¸ã‚’éšå±¤çš„ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€ãƒ„ãƒªãƒ¼æ§‹é€ ã§ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé«˜é€Ÿã‹ã¤æ–‡è„ˆã‚’ä¿æŒã—ãŸæ¤œç´¢ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### ğŸ¯ ä¸»ãªç‰¹å¾´

- **éšå±¤çš„ãƒ„ãƒªãƒ¼æ§‹é€ **: æ–‡æ›¸ã‚’å†å¸°çš„ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€å¤šéšå±¤ã®ãƒ„ãƒªãƒ¼ã‚’æ§‹ç¯‰
- **åŠ¹ç‡çš„ãªæ¤œç´¢**: O(log n)ã®æ¤œç´¢è¤‡é›‘åº¦ã§å¤§è¦æ¨¡æ–‡æ›¸ã«ã‚‚å¯¾å¿œ
- **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒ**: å„ãƒ¬ãƒ™ãƒ«ã§è¦ç´„ã‚’ç”Ÿæˆã—ã€å¤§å±€çš„ãªç†è§£ã‚’ç¶­æŒ
- **100%ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹**: Granite Code 8B (LLM) + mxbai-embed-large (Embeddings)
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«**: æ•°åä¸‡æ–‡å­—ã®æ–‡æ›¸ã§ã‚‚é«˜é€Ÿå‡¦ç†

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### å‰ææ¡ä»¶

1. **Ollamaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«** ([å…¬å¼ã‚µã‚¤ãƒˆ](https://ollama.ai/))
2. **å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã®å–å¾—**:
```bash
ollama pull granite-code:8b
ollama pull mxbai-embed-large
```

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -U langchain langchain-community langchain-ollama scikit-learn numpy
```

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```python
from langchain_ollama import ChatOllama, OllamaEmbeddings
from raptor import RAPTORRetriever

# LLMã¨Embeddingsã®åˆæœŸåŒ–
llm = ChatOllama(model="granite-code:8b", base_url="http://localhost:11434", temperature=0)
embeddings = OllamaEmbeddings(model="mxbai-embed-large", base_url="http://localhost:11434")

# RAPTORãƒ¬ãƒˆãƒªãƒ¼ãƒãƒ¼ã®ä½œæˆ
raptor = RAPTORRetriever(
    embeddings_model=embeddings,
    llm=llm,
    max_clusters=3,   # å„ãƒ¬ãƒ™ãƒ«ã§æœ€å¤§3ã‚¯ãƒ©ã‚¹ã‚¿
    max_depth=2,      # æœ€å¤§2éšå±¤
)

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
raptor.index("your_document.txt")

# æ¤œç´¢å®Ÿè¡Œ
results = raptor.retrieve("æ¤œç´¢ã‚¯ã‚¨ãƒª", top_k=3)
for i, doc in enumerate(results, 1):
    print(f"Result {i}: {doc.page_content[:200]}...")
```

## ğŸ“Š æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

### ãƒ†ã‚¹ãƒˆç’°å¢ƒ
- **æ–‡æ›¸ã‚µã‚¤ã‚º**: 624,212æ–‡å­—
- **ãƒãƒ£ãƒ³ã‚¯æ•°**: 864å€‹
- **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: NVIDIA RTX 4060 Ti 16GB

### çµæœ

| æŒ‡æ¨™ | å€¤ |
|------|-----|
| **ãƒ„ãƒªãƒ¼æ§‹ç¯‰æ™‚é–“** | ~5åˆ† (è¦ç´„ç”Ÿæˆå«ã‚€) |
| **æ¤œç´¢æ™‚é–“** | <1ç§’ |
| **ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰æ•°** | 9 |
| **åœ§ç¸®ç‡** | 96x (864 â†’ 9) |
| **æ¤œç´¢ç²¾åº¦** | 0.63-0.67 (ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦) |

### å¾“æ¥æ‰‹æ³•ã¨ã®æ¯”è¼ƒ

```
å˜ç´”ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢:  O(n)   - å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒ£ãƒ³
RAPTOR:           O(log n) - éšå±¤çš„æ¢ç´¢
ColBERT:          O(nÃ—m)  - ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«æ¯”è¼ƒ
```

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
Root (864 docs)
â”œâ”€â”€ Cluster 0 (344 docs)
â”‚   â”œâ”€â”€ Cluster 0-0 (81 docs)  â†’ Leaf
â”‚   â”œâ”€â”€ Cluster 0-1 (135 docs) â†’ Leaf
â”‚   â””â”€â”€ Cluster 0-2 (128 docs) â†’ Leaf
â”œâ”€â”€ Cluster 1 (219 docs)
â”‚   â”œâ”€â”€ Cluster 1-0 (151 docs) â†’ Leaf
â”‚   â”œâ”€â”€ Cluster 1-1 (19 docs)  â†’ Leaf
â”‚   â””â”€â”€ Cluster 1-2 (49 docs)  â†’ Leaf
â””â”€â”€ Cluster 2 (301 docs)
    â”œâ”€â”€ Cluster 2-0 (75 docs)  â†’ Leaf
    â”œâ”€â”€ Cluster 2-1 (86 docs)  â†’ Leaf
    â””â”€â”€ Cluster 2-2 (140 docs) â†’ Leaf
```

## ğŸ”§ è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|-----------|------|
| `max_clusters` | 5 | å„ãƒ¬ãƒ™ãƒ«ã§ã®æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿æ•° |
| `max_depth` | 3 | ãƒ„ãƒªãƒ¼ã®æœ€å¤§æ·±ã• |
| `chunk_size` | 1000 | æ–‡æ›¸ãƒãƒ£ãƒ³ã‚¯ã®ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰ |
| `chunk_overlap` | 200 | ãƒãƒ£ãƒ³ã‚¯é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ— |

### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰

**å°è¦æ¨¡æ–‡æ›¸ï¼ˆ<10ä¸‡æ–‡å­—ï¼‰**:
```python
raptor = RAPTORRetriever(
    max_clusters=2,
    max_depth=2,
    chunk_size=500
)
```

**ä¸­è¦æ¨¡æ–‡æ›¸ï¼ˆ10-50ä¸‡æ–‡å­—ï¼‰**:
```python
raptor = RAPTORRetriever(
    max_clusters=3,
    max_depth=2,
    chunk_size=1000
)
```

**å¤§è¦æ¨¡æ–‡æ›¸ï¼ˆ>50ä¸‡æ–‡å­—ï¼‰**:
```python
raptor = RAPTORRetriever(
    max_clusters=5,
    max_depth=3,
    chunk_size=1500
)
```

## ğŸ“š ä½¿ç”¨ä¾‹

### ä¾‹1: åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³• (example.py)

test.txt ã‚’ä½¿ã£ãŸåŸºæœ¬çš„ãªRAGæ¤œç´¢ï¼š

```python
raptor.index("test.txt")
results = raptor.retrieve("philosophy", top_k=3)

# å‡ºåŠ›ä¾‹:
# Selected cluster 0 at depth 0 (similarity: 0.6691)
# Selected cluster 2 at depth 1 (similarity: 0.6587)
# â†’ ãƒ—ãƒ©ãƒˆãƒ³ã®å“²å­¦çš„ä¿¡æ¡ã«é–¢ã™ã‚‹3ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
```

**å®Ÿè¡Œæ–¹æ³•**:
```bash
python example.py
```

### ä¾‹2: Wikipedia RAG (example2-wiki.py)

Wikipedia ã‹ã‚‰å‹•çš„ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¦RAGæ¤œç´¢ï¼š

```python
import requests
from raptor import RAPTORRetriever

# Wikipedia APIã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
def get_wikipedia_page(title: str) -> str:
    URL = "https://en.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "format": "json",
        "titles": title,
        "prop": "extracts",
        "explaintext": True,
    }
    headers = {"User-Agent": "RAPTOR_RAG_Example/1.0"}
    response = requests.get(URL, params=params, headers=headers)
    data = response.json()
    page = next(iter(data["query"]["pages"].values()))
    return page["extract"] if "extract" in page else None

# Miyazaki Hayaoã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
wiki_content = get_wikipedia_page("Hayao_Miyazaki")

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
import tempfile
with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', delete=False) as f:
    f.write(wiki_content)
    tmp_path = f.name

raptor.index(tmp_path)

# æ¤œç´¢å®Ÿè¡Œ
results = raptor.retrieve("What animation studio did Miyazaki found?", top_k=3)

# å‡ºåŠ›ä¾‹:
# âœ… Fetched 70,159 characters
# Split into 118 chunks
# Selected cluster 0 at depth 0 (similarity: 0.7885)
# Selected cluster 1 at depth 1 (similarity: 0.7720)
# â†’ Studio Ghibli ã®è¨­ç«‹ã«é–¢ã™ã‚‹æƒ…å ±ã‚’å–å¾—
```

**å®Ÿè¡Œæ–¹æ³•**:
```bash
python example2-wiki.py
```

**ä¸»ãªæ©Ÿèƒ½**:
- ğŸ“¥ Wikipedia API ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
- ğŸŒ³ 70,159æ–‡å­— â†’ 118ãƒãƒ£ãƒ³ã‚¯ â†’ 9ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰ã«éšå±¤åŒ–
- ğŸ” è¤‡æ•°ã‚¯ã‚¨ãƒªã§ã®æ¤œç´¢ãƒ‡ãƒ¢ï¼ˆStudio Ghibliã€å—è³æ­´ã€ä»£è¡¨ä½œï¼‰
- ğŸ“Š é«˜ç²¾åº¦æ¤œç´¢ï¼ˆé¡ä¼¼åº¦ 0.73-0.78ï¼‰

## ğŸ”¬ æŠ€è¡“è©³ç´°

### ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

RAPTORã¯K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ã€æ„å‘³çš„ã«é¡ä¼¼ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¾ã™ï¼š

1. **ãƒ™ã‚¯ãƒˆãƒ«åŒ–**: mxbai-embed-large (1024æ¬¡å…ƒ)ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åŸ‹ã‚è¾¼ã¿
2. **ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: K-means (k=max_clusters)ã§åˆ†é¡
3. **è¦ç´„ç”Ÿæˆ**: Granite Code 8Bã§å„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’è¦ç´„
4. **å†å¸°å‡¦ç†**: å„ã‚¯ãƒ©ã‚¹ã‚¿ã«å¯¾ã—ã¦å†å¸°çš„ã«å‡¦ç†

### æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```
1. ãƒ«ãƒ¼ãƒˆãƒãƒ¼ãƒ‰ã‹ã‚‰é–‹å§‹
2. ã‚¯ã‚¨ãƒªã¨å„ã‚¯ãƒ©ã‚¹ã‚¿ã®è¦ç´„ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
3. æœ€ã‚‚é¡ä¼¼åº¦ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é¸æŠ
4. é¸æŠã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ã®å­ãƒãƒ¼ãƒ‰ã§å†å¸°çš„ã«æ¤œç´¢
5. ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰ã§æœ€çµ‚çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
```

## ğŸ¨ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ã‚«ã‚¹ã‚¿ãƒ è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨

```python
class CustomRAPTOR(RAPTORRetriever):
    def summarize_cluster(self, documents):
        combined_text = "\n\n".join([doc.page_content for doc in documents])
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = ChatPromptTemplate.from_template(
            "ä»¥ä¸‹ã®æŠ€è¡“æ–‡æ›¸ã‚’å°‚é–€å®¶å‘ã‘ã«è¦ç´„ã—ã¦ãã ã•ã„:\n\n{text}"
        )
        
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"text": combined_text[:4000]})
```

### ç•°ãªã‚‹LLMã®ä½¿ç”¨

```python
# GPT-4ã®ä½¿ç”¨ä¾‹
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4", temperature=0)
raptor = RAPTORRetriever(embeddings_model=embeddings, llm=llm)
```

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

**Q: "Connection refused" ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹**
```bash
# OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
ollama serve
```

**Q: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹**
```python
# chunk_sizeã‚’å°ã•ãã—ã¦èª¿æ•´
raptor = RAPTORRetriever(chunk_size=500)
```

**Q: æ¤œç´¢ç²¾åº¦ãŒä½ã„**
```python
# ã‚ˆã‚Šæ·±ã„éšå±¤ã¨ã‚ˆã‚Šå¤šãã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’è©¦ã™
raptor = RAPTORRetriever(max_clusters=5, max_depth=3)
```

## ğŸ“ˆ ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

- [ ] PostgreSQLãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¨ã®çµ±åˆ
- [ ] éåŒæœŸå‡¦ç†å¯¾å¿œ
- [ ] Web UIã®è¿½åŠ 
- [ ] è¤‡æ•°ãƒ‘ã‚¹æ¤œç´¢ã®ã‚µãƒãƒ¼ãƒˆ
- [ ] å‹•çš„ã‚¯ãƒ©ã‚¹ã‚¿æ•°èª¿æ•´
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

## ğŸ¤ è²¢çŒ®

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ­“è¿ã—ã¾ã™ï¼å¤§ããªå¤‰æ›´ã®å ´åˆã¯ã€ã¾ãšissueã‚’é–‹ã„ã¦å¤‰æ›´å†…å®¹ã‚’è­°è«–ã—ã¦ãã ã•ã„ã€‚

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

[MIT License](LICENSE)

## ğŸ‘¥ è‘—è€…

- é–‹ç™ºè€…: [Your Name]
- GitHub: [@yourusername]

## ğŸ™ è¬è¾

- [LangChain](https://github.com/langchain-ai/langchain) - RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- [Ollama](https://ollama.ai/) - ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œç’°å¢ƒ
- RAPTORè«–æ–‡è‘—è€… - å…ƒã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­è¨ˆ

## ğŸ“– å‚è€ƒæ–‡çŒ®

- RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval (Original Paper)
- LangChain Documentation
- scikit-learn K-means Implementation

---

â­ ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒå½¹ç«‹ã£ãŸå ´åˆã¯ã€GitHubã§ã‚¹ã‚¿ãƒ¼ã‚’ãŠé¡˜ã„ã—ã¾ã™ï¼
