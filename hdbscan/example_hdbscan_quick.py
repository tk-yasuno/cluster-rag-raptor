"""
HDBSCANå˜ç‹¬ãƒ†ã‚¹ãƒˆ - é«˜é€Ÿç‰ˆ
å°ã•ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å‹•ä½œç¢ºèª
"""

from langchain_ollama import ChatOllama, OllamaEmbeddings
from raptor_hdbscan import RAPTORRetrieverHDBSCAN
import time


def quick_test_hdbscan():
    """HDBSCANã®å˜ç‹¬ãƒ†ã‚¹ãƒˆï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
    
    print("=" * 80)
    print("ğŸš€ HDBSCAN RAPTOR - Quick Test")
    print("=" * 80)
    print()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    llm = ChatOllama(
        model="granite-code:8b",
        base_url="http://localhost:11434",
        temperature=0
    )
    
    embeddings_model = OllamaEmbeddings(
        model="mxbai-embed-large",
        base_url="http://localhost:11434"
    )
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_query = "philosophy"
    
    # HDBSCANï¼ˆCosineè·é›¢ï¼‰
    print("ğŸ“Š Testing HDBSCAN with Cosine metric")
    print("-" * 80)
    
    raptor_hdbscan = RAPTORRetrieverHDBSCAN(
        embeddings_model=embeddings_model,
        llm=llm,
        min_cluster_size=10,        # 864ãƒãƒ£ãƒ³ã‚¯ç”¨ã«èª¿æ•´
        min_samples=3,              # é©åº¦ã«ç·©ã
        max_depth=2,                # æ·±ã•2ã«åˆ¶é™
        chunk_size=1000,
        chunk_overlap=200,
        metric='cosine',            # ã‚³ã‚µã‚¤ãƒ³è·é›¢ï¼ˆæ­£è¦åŒ–å¾Œã«Euclideanã§è¨ˆç®—ï¼‰
        exclude_noise=True
    )
    
    start_time = time.time()
    
    # å¤§ãã„ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆï¼ˆ864ãƒãƒ£ãƒ³ã‚¯ï¼‰
    print("\nğŸ“– Note: Using full test.txt file (864 chunks)")
    print("   min_cluster_size=10, min_samples=3")
    raptor_hdbscan.index("test.txt")
    
    build_time = time.time() - start_time
    
    start_time = time.time()
    results = raptor_hdbscan.retrieve(test_query, top_k=3)
    query_time = time.time() - start_time
    
    # çµæœè¡¨ç¤º
    print(f"\n{'='*80}")
    print(f"âœ… HDBSCAN Test Results")
    print(f"{'='*80}")
    print(f"Build time: {build_time:.2f}ç§’")
    print(f"Query time: {query_time:.3f}ç§’")
    
    print(f"\nğŸ“Š Noise Statistics:")
    print(f"   Total noise chunks removed: {raptor_hdbscan.noise_stats['total_noise_chunks']}")
    if raptor_hdbscan.noise_stats['noise_by_depth']:
        print(f"   Noise by depth: {dict(raptor_hdbscan.noise_stats['noise_by_depth'])}")
    
    print(f"\nTop 3 Results:")
    for i, doc in enumerate(results, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"\n{i}. Similarity: {similarity}")
        print(f"   Preview: {doc.page_content[:200]}...")
    
    print("\n" + "=" * 80)
    print("ğŸ¯ Quick Test Complete!")
    print("   - HDBSCAN automatically found optimal cluster count")
    print(f"   - Removed {raptor_hdbscan.noise_stats['total_noise_chunks']} noisy chunks")
    print("   - Used cosine distance for semantic similarity")
    print("=" * 80)


if __name__ == "__main__":
    quick_test_hdbscan()
