"""
RAPTOR HDBSCAN vs GMM vs K-means Comparison Demo
HDBSCANã«ã‚ˆã‚‹ãƒã‚¤ã‚ºé™¤å»ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°è‡ªå‹•æ±ºå®šã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

æ¯”è¼ƒå¯¾è±¡:
1. K-means (å›ºå®šã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°)
2. GMM + BIC (æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°è‡ªå‹•é¸æŠ)
3. HDBSCAN (ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°è‡ªå‹•æ±ºå®š + ãƒã‚¤ã‚ºé™¤å»)
"""

from langchain_ollama import ChatOllama, OllamaEmbeddings
from raptor_hdbscan import RAPTORRetrieverHDBSCAN
from raptor_gmm import RAPTORRetrieverGMM
from raptor import RAPTORRetriever
import time


def compare_clustering_methods():
    """K-meansã€GMM+BICã€HDBSCANã®æ¯”è¼ƒ"""
    
    print("=" * 80)
    print("ğŸ”¬ RAPTOR: Advanced Clustering Method Comparison")
    print("   K-means vs GMM+BIC vs HDBSCAN (with noise removal)")
    print("=" * 80)
    print()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    llm = ChatOllama(
        model="granite-code:8b",
        base_url="http://localhost:11434",
        temperature=0
    )
    
    embeddings_model = OllamaEmbeddings(
        model="mxbai-embed-large",
        base_url="http://localhost:11434"
    )
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_query = "philosophy"
    
    # ==========================================
    # Method 1: å¾“æ¥ã®K-meansï¼ˆå›ºå®šã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ï¼‰
    # ==========================================
    print("ğŸ“Š Method 1: K-means (Fixed cluster count = 3)")
    print("-" * 80)
    
    raptor_kmeans = RAPTORRetriever(
        embeddings_model=embeddings_model,
        llm=llm,
        max_clusters=3,
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200
    )
    
    start_time = time.time()
    raptor_kmeans.index("test.txt")
    kmeans_build_time = time.time() - start_time
    
    start_time = time.time()
    results_kmeans = raptor_kmeans.retrieve(test_query, top_k=3)
    kmeans_query_time = time.time() - start_time
    
    print(f"\nâœ… K-means Results:")
    print(f"   Build time: {kmeans_build_time:.2f}ç§’")
    print(f"   Query time: {kmeans_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_kmeans, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    print("\n")
    
    # ==========================================
    # Method 2: GMM with BICï¼ˆæœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°è‡ªå‹•é¸æŠï¼‰
    # ==========================================
    print("ğŸ“Š Method 2: GMM with BIC (Auto-optimal cluster count)")
    print("-" * 80)
    
    raptor_gmm = RAPTORRetrieverGMM(
        embeddings_model=embeddings_model,
        llm=llm,
        max_clusters=5,      # BICã§æ¢ç´¢ã™ã‚‹æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°
        min_clusters=2,      # BICã§æ¢ç´¢ã™ã‚‹æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200,
        use_bic=True,        # BICã«ã‚ˆã‚‹æœ€é©åŒ–ON
        clustering_method="gmm"  # GMMã‚’ä½¿ç”¨
    )
    
    start_time = time.time()
    raptor_gmm.index("test.txt")
    gmm_build_time = time.time() - start_time
    
    start_time = time.time()
    results_gmm = raptor_gmm.retrieve(test_query, top_k=3)
    gmm_query_time = time.time() - start_time
    
    print(f"\nâœ… GMM+BIC Results:")
    print(f"   Build time: {gmm_build_time:.2f}ç§’")
    print(f"   Query time: {gmm_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_gmm, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    print("\n")
    
    # ==========================================
    # Method 3: HDBSCANï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°è‡ªå‹•æ±ºå®š + ãƒã‚¤ã‚ºé™¤å»ï¼‰
    # ==========================================
    print("ğŸ“Š Method 3: HDBSCAN (Auto cluster count + Noise removal)")
    print("-" * 80)
    
    raptor_hdbscan = RAPTORRetrieverHDBSCAN(
        embeddings_model=embeddings_model,
        llm=llm,
        min_cluster_size=15,    # ã‚¯ãƒ©ã‚¹ã‚¿ã®æœ€å°ã‚µã‚¤ã‚º
        min_samples=5,          # å¯†åº¦æ¨å®šã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200,
        metric='euclidean',     # è·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯
        exclude_noise=True      # ãƒã‚¤ã‚ºé™¤å»ON
    )
    
    start_time = time.time()
    raptor_hdbscan.index("test.txt")
    hdbscan_build_time = time.time() - start_time
    
    start_time = time.time()
    results_hdbscan = raptor_hdbscan.retrieve(test_query, top_k=3)
    hdbscan_query_time = time.time() - start_time
    
    print(f"\nâœ… HDBSCAN Results:")
    print(f"   Build time: {hdbscan_build_time:.2f}ç§’")
    print(f"   Query time: {hdbscan_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_hdbscan, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    # ãƒã‚¤ã‚ºçµ±è¨ˆã‚’è¡¨ç¤º
    print(f"\n   ğŸ“Š Noise Statistics:")
    print(f"      Total noise chunks removed: {raptor_hdbscan.noise_stats['total_noise_chunks']}")
    if raptor_hdbscan.noise_stats['noise_by_depth']:
        print(f"      Noise by depth: {dict(raptor_hdbscan.noise_stats['noise_by_depth'])}")
    
    print("\n")
    
    # ==========================================
    # Method 4: HDBSCAN with cosine metric
    # ==========================================
    print("ğŸ“Š Method 4: HDBSCAN (Cosine metric)")
    print("-" * 80)
    
    raptor_hdbscan_cosine = RAPTORRetrieverHDBSCAN(
        embeddings_model=embeddings_model,
        llm=llm,
        min_cluster_size=15,
        min_samples=5,
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200,
        metric='cosine',        # ã‚³ã‚µã‚¤ãƒ³è·é›¢ã‚’ä½¿ç”¨
        exclude_noise=True
    )
    
    start_time = time.time()
    raptor_hdbscan_cosine.index("test.txt")
    hdbscan_cosine_build_time = time.time() - start_time
    
    start_time = time.time()
    results_hdbscan_cosine = raptor_hdbscan_cosine.retrieve(test_query, top_k=3)
    hdbscan_cosine_query_time = time.time() - start_time
    
    print(f"\nâœ… HDBSCAN (Cosine) Results:")
    print(f"   Build time: {hdbscan_cosine_build_time:.2f}ç§’")
    print(f"   Query time: {hdbscan_cosine_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_hdbscan_cosine, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    # ãƒã‚¤ã‚ºçµ±è¨ˆã‚’è¡¨ç¤º
    print(f"\n   ğŸ“Š Noise Statistics:")
    print(f"      Total noise chunks removed: {raptor_hdbscan_cosine.noise_stats['total_noise_chunks']}")
    if raptor_hdbscan_cosine.noise_stats['noise_by_depth']:
        print(f"      Noise by depth: {dict(raptor_hdbscan_cosine.noise_stats['noise_by_depth'])}")
    
    # ==========================================
    # æ¯”è¼ƒã‚µãƒãƒªãƒ¼
    # ==========================================
    print("\n" + "=" * 80)
    print("ğŸ“Š Performance Comparison Summary")
    print("=" * 80)
    print()
    
    print("| Method                  | Build Time | Query Time | Note                           |")
    print("|-------------------------|------------|------------|--------------------------------|")
    print(f"| K-means (fixed)         | {kmeans_build_time:>7.2f}ç§’  | {kmeans_query_time:>7.3f}ç§’ | Manual cluster count           |")
    print(f"| GMM + BIC               | {gmm_build_time:>7.2f}ç§’  | {gmm_query_time:>7.3f}ç§’ | Auto-optimal, flexible         |")
    print(f"| HDBSCAN (euclidean)     | {hdbscan_build_time:>7.2f}ç§’  | {hdbscan_query_time:>7.3f}ç§’ | Auto + noise removal           |")
    print(f"| HDBSCAN (cosine)        | {hdbscan_cosine_build_time:>7.2f}ç§’  | {hdbscan_cosine_query_time:>7.3f}ç§’ | Semantic distance based        |")
    
    print("\nğŸ¯ Key Findings:")
    print("1. HDBSCAN automatically determines optimal cluster count")
    print("2. Noise removal improves semantic quality by excluding weak chunks")
    print("3. Cosine metric may better capture semantic similarity")
    print("4. Build time increases slightly but search quality improves")
    print(f"5. HDBSCAN removed {raptor_hdbscan.noise_stats['total_noise_chunks']} noise chunks (euclidean)")
    print(f"6. HDBSCAN removed {raptor_hdbscan_cosine.noise_stats['total_noise_chunks']} noise chunks (cosine)")
    
    print("\nğŸ’¡ Recommendations:")
    print("â€¢ Use HDBSCAN for automatic clustering with noise detection")
    print("â€¢ Use cosine metric for semantic embeddings (e.g., mxbai-embed-large)")
    print("â€¢ Tune min_cluster_size based on document granularity")
    print("â€¢ Lower min_cluster_size for finer-grained clusters")
    print("â€¢ Higher min_cluster_size for more conservative clustering")
    
    print("\nğŸ”§ HDBSCAN Parameter Guide:")
    print("â€¢ min_cluster_size: æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (å¤§ãã„ã»ã©ä¿å®ˆçš„)")
    print("  - Small docs (100-500 chars): 5-10")
    print("  - Medium docs (500-1500 chars): 10-20")
    print("  - Large docs (1500+ chars): 15-30")
    print("â€¢ min_samples: å¯†åº¦æ¨å®šã®ã‚µãƒ³ãƒ—ãƒ«æ•° (é€šå¸¸ã¯min_cluster_sizeã®1/3)")
    print("â€¢ metric: 'euclidean' (æ±ç”¨) or 'cosine' (semantic)")
    
    print("\n" + "=" * 80)


def test_different_parameters():
    """HDBSCANã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“"""
    
    print("\n" + "=" * 80)
    print("ğŸ§ª HDBSCAN Parameter Tuning Experiment")
    print("=" * 80)
    print()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    llm = ChatOllama(
        model="granite-code:8b",
        base_url="http://localhost:11434",
        temperature=0
    )
    
    embeddings_model = OllamaEmbeddings(
        model="mxbai-embed-large",
        base_url="http://localhost:11434"
    )
    
    test_query = "philosophy"
    
    # ç•°ãªã‚‹min_cluster_sizeã§ãƒ†ã‚¹ãƒˆ
    cluster_sizes = [5, 10, 15, 20]
    
    results_summary = []
    
    for min_size in cluster_sizes:
        print(f"\n{'='*80}")
        print(f"Testing min_cluster_size = {min_size}")
        print(f"{'='*80}")
        
        raptor = RAPTORRetrieverHDBSCAN(
            embeddings_model=embeddings_model,
            llm=llm,
            min_cluster_size=min_size,
            min_samples=max(1, min_size // 3),  # 1/3ãƒ«ãƒ¼ãƒ«
            max_depth=2,
            chunk_size=1000,
            chunk_overlap=200,
            metric='cosine',
            exclude_noise=True
        )
        
        start_time = time.time()
        raptor.index("test.txt")
        build_time = time.time() - start_time
        
        results = raptor.retrieve(test_query, top_k=3)
        
        results_summary.append({
            'min_cluster_size': min_size,
            'build_time': build_time,
            'noise_removed': raptor.noise_stats['total_noise_chunks'],
            'top_similarity': results[0].metadata.get('similarity', 'N/A') if results else 'N/A'
        })
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ“Š Parameter Tuning Summary")
    print("=" * 80)
    print()
    print("| min_cluster_size | Build Time | Noise Removed | Top Similarity |")
    print("|------------------|------------|---------------|----------------|")
    for res in results_summary:
        print(f"| {res['min_cluster_size']:>16} | {res['build_time']:>7.2f}ç§’  | {res['noise_removed']:>13} | {res['top_similarity']:>14} |")
    
    print("\nğŸ’¡ Observations:")
    print("â€¢ Larger min_cluster_size â†’ More conservative clustering")
    print("â€¢ Larger min_cluster_size â†’ More noise detected")
    print("â€¢ Optimal value depends on document characteristics")
    print("=" * 80)


if __name__ == "__main__":
    # ãƒ¡ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“
    compare_clustering_methods()
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # test_different_parameters()
