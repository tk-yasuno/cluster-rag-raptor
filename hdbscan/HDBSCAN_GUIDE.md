# RAPTOR with HDBSCAN - ãƒã‚¤ã‚ºé™¤å»æ©Ÿèƒ½ä»˜ãéšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

## ğŸ¯ æ¦‚è¦

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) ã«HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) ã‚’çµ±åˆã—ã€**æ„å‘³ã®è–„ã„ãƒãƒ£ãƒ³ã‚¯ã®è‡ªå‹•é™¤å»**ã¨**ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è‡ªå‹•æ±ºå®š**ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## ğŸŒŸ HDBSCANå°å…¥ã®åˆ©ç‚¹

### âœ… ä¸»è¦ãªåˆ©ç‚¹

1. **ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è‡ªå‹•æ±ºå®š**
   - K-meansã®ã‚ˆã†ãª`k`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦
   - æ–‡æ›¸æ§‹é€ ã«è‡ªç„¶ã«é©å¿œ
   - ãƒ‡ãƒ¼ã‚¿é§†å‹•ã®ã‚¯ãƒ©ã‚¹ã‚¿å½¢æˆ

2. **ãƒã‚¤ã‚ºæ¤œå‡ºãƒ»é™¤å»**
   - æ„å‘³ã®è–„ã„ãƒãƒ£ãƒ³ã‚¯ã‚’è‡ªå‹•æ¤œå‡º
   - ãƒã‚¤ã‚ºãƒ©ãƒ™ãƒ« `-1` ã§è­˜åˆ¥
   - æ¤œç´¢ç²¾åº¦ã®å‘ä¸Š

3. **éšå±¤æ€§ã®æ´»ç”¨**
   - Condensed treeã«ã‚ˆã‚‹çœŸã®éšå±¤æ§‹é€ 
   - å¯†åº¦ãƒ™ãƒ¼ã‚¹ã®è‡ªç„¶ãªéšå±¤å½¢æˆ
   - RAPTORã®ãƒ„ãƒªãƒ¼æ§‹é€ ã¨ç›¸æ€§è‰¯å¥½

4. **é«˜æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ã¨ã®ç›¸æ€§**
   - mxbai-embed-largeã®ã‚ˆã†ãªå¤§è¦æ¨¡embeddingså‘ã
   - ã‚³ã‚µã‚¤ãƒ³è·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯å¯¾å¿œ
   - æ„å‘³çš„é¡ä¼¼åº¦ã‚’æ­£ç¢ºã«æ‰ãˆã‚‹

## ğŸ†š æ‰‹æ³•æ¯”è¼ƒ

| æ‰‹æ³• | ã‚¯ãƒ©ã‚¹ã‚¿æ•°æ±ºå®š | ãƒã‚¤ã‚ºé™¤å» | éšå±¤æ€§ | ä¸»ãªç”¨é€” |
|------|---------------|-----------|--------|---------|
| **K-means** | æ‰‹å‹•å›ºå®š | âŒ | âŒ | æ—¢çŸ¥ã®ã‚¯ãƒ©ã‚¹ã‚¿æ§‹é€  |
| **GMM + BIC** | è‡ªå‹•ï¼ˆBICæœ€é©åŒ–ï¼‰ | âŒ | âŒ | è¤‡é›‘ãªåˆ†å¸ƒ |
| **HDBSCAN** | è‡ªå‹•ï¼ˆå¯†åº¦ãƒ™ãƒ¼ã‚¹ï¼‰ | âœ… | âœ… | æœªçŸ¥æ§‹é€  + å“è³ªé‡è¦– |

## ğŸ› ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
pip install -U langchain langchain-community langchain-ollama scikit-learn numpy

# HDBSCAN
pip install hdbscan
```

## ğŸš€ ä½¿ã„æ–¹

### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```python
from langchain_ollama import ChatOllama, OllamaEmbeddings
from raptor_hdbscan import RAPTORRetrieverHDBSCAN

# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
llm = ChatOllama(
    model="granite-code:8b",
    base_url="http://localhost:11434",
    temperature=0
)

embeddings_model = OllamaEmbeddings(
    model="mxbai-embed-large",
    base_url="http://localhost:11434"
)

# RAPTOR with HDBSCAN
raptor = RAPTORRetrieverHDBSCAN(
    embeddings_model=embeddings_model,
    llm=llm,
    min_cluster_size=15,    # é‡è¦: ã‚¯ãƒ©ã‚¹ã‚¿ã®æœ€å°ã‚µã‚¤ã‚º
    min_samples=5,          # å¯†åº¦æ¨å®šç”¨
    max_depth=2,
    chunk_size=1000,
    chunk_overlap=200,
    metric='cosine',        # 'euclidean' or 'cosine'
    exclude_noise=True      # ãƒã‚¤ã‚ºé™¤å»ON
)

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
raptor.index("your_document.txt")

# æ¤œç´¢
results = raptor.retrieve("your query", top_k=3)

# ãƒã‚¤ã‚ºçµ±è¨ˆã‚’ç¢ºèª
print(f"Removed noise chunks: {raptor.noise_stats['total_noise_chunks']}")
```

### æ¯”è¼ƒå®Ÿé¨“ã®å®Ÿè¡Œ

```bash
# å…¨æ‰‹æ³•ã®æ¯”è¼ƒï¼ˆK-means, GMM+BIC, HDBSCANï¼‰
python example_hdbscan_comparison.py

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“
# example_hdbscan_comparison.pyå†…ã®test_different_parameters()ã‚’æœ‰åŠ¹åŒ–
```

## ğŸ”§ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰

### `min_cluster_size` ã®é¸ã³æ–¹

ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã«åŸºã¥ãæ¨å¥¨å€¤:

```python
# å°ã•ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (100-500æ–‡å­—)
min_cluster_size = 5-10

# ä¸­è¦æ¨¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (500-1500æ–‡å­—)
min_cluster_size = 10-20

# å¤§è¦æ¨¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (1500æ–‡å­—ä»¥ä¸Š)
min_cluster_size = 15-30
```

**ãƒ«ãƒ¼ãƒ«:**
- å€¤ãŒ**å¤§ãã„**ã»ã©ä¿å®ˆçš„ï¼ˆãƒã‚¤ã‚ºå¤šã‚ã€ã‚¯ãƒ©ã‚¹ã‚¿å°‘ãªã‚ï¼‰
- å€¤ãŒ**å°ã•ã„**ã»ã©ç´°ã‹ã„ç²’åº¦ï¼ˆãƒã‚¤ã‚ºå°‘ãªã‚ã€ã‚¯ãƒ©ã‚¹ã‚¿å¤šã‚ï¼‰

### `min_samples` ã®é¸ã³æ–¹

ä¸€èˆ¬çš„ãªãƒ«ãƒ¼ãƒ«: `min_samples = min_cluster_size / 3`

```python
min_cluster_size = 15
min_samples = 5  # 15 / 3 = 5
```

### `metric` ã®é¸ã³æ–¹

| ãƒ¡ãƒˆãƒªãƒƒã‚¯ | æ¨å¥¨ã‚±ãƒ¼ã‚¹ | ç‰¹å¾´ |
|-----------|-----------|------|
| `'euclidean'` | æ±ç”¨çš„ãªç”¨é€” | æ¨™æº–çš„ãªè·é›¢ |
| `'cosine'` | æ„å‘³çš„åŸ‹ã‚è¾¼ã¿ | æ–¹å‘æ€§ã‚’é‡è¦–ã€mxbai-embed-largeæ¨å¥¨ |

### `exclude_noise` ã®è¨­å®š

```python
# ãƒã‚¤ã‚ºã‚’é™¤å¤–ï¼ˆæ¨å¥¨ï¼‰
exclude_noise = True

# ãƒã‚¤ã‚ºã‚‚ä¿æŒï¼ˆå®Ÿé¨“çš„ï¼‰
exclude_noise = False
```

## ğŸ“Š å®Ÿé¨“çµæœä¾‹

### ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ

```
ğŸ—‘ï¸  Noise Statistics
================================================================================
   Total noise chunks excluded: 12
   Noise by depth:
     Depth 0: 8 chunks
     Depth 1: 4 chunks
================================================================================
```

### æ€§èƒ½æ¯”è¼ƒ

| Method | Build Time | Query Time | Noise Removed | Note |
|--------|-----------|-----------|---------------|------|
| K-means (fixed) | 15.23ç§’ | 0.045ç§’ | 0 | å›ºå®š3ã‚¯ãƒ©ã‚¹ã‚¿ |
| GMM + BIC | 18.45ç§’ | 0.047ç§’ | 0 | è‡ªå‹•æœ€é©åŒ– |
| HDBSCAN (euclidean) | 16.89ç§’ | 0.044ç§’ | 12 | è‡ªå‹•+ãƒã‚¤ã‚ºé™¤å» |
| HDBSCAN (cosine) | 17.12ç§’ | 0.043ç§’ | 15 | æ„å‘³çš„è·é›¢ |

## ğŸ§ª ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿé¨“

### å®Ÿé¨“1: åŸºæœ¬æ¯”è¼ƒ

```bash
python example_hdbscan_comparison.py
```

**ç¢ºèªé …ç›®:**
- ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰æ•°
- åœ§ç¸®ç‡
- æ¤œç´¢ç²¾åº¦
- ãƒã‚¤ã‚ºé™¤å»æ•°

### å®Ÿé¨“2: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

`example_hdbscan_comparison.py` å†…ã§ `test_different_parameters()` ã‚’æœ‰åŠ¹åŒ–:

```python
if __name__ == "__main__":
    compare_clustering_methods()
    test_different_parameters()  # ã‚³ãƒ¡ãƒ³ãƒˆè§£é™¤
```

**ãƒ†ã‚¹ãƒˆã™ã‚‹å€¤:**
- `min_cluster_size`: [5, 10, 15, 20]
- `metric`: ['euclidean', 'cosine']

## ğŸ“ ç†è«–èƒŒæ™¯

### HDBSCANã®å‹•ä½œåŸç†

1. **ç›¸äº’åˆ°é”è·é›¢ã®è¨ˆç®—**
   - å„ç‚¹é–“ã®å¯†åº¦ã‚’è€ƒæ…®ã—ãŸè·é›¢
   - ãƒã‚¤ã‚ºã«å¼·ã„è·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯

2. **éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**
   - Single linkage clustering
   - Minimum spanning treeæ§‹ç¯‰

3. **Condensed treeç”Ÿæˆ**
   - éšå±¤æ§‹é€ ã®å®‰å®šéƒ¨åˆ†ã‚’æŠ½å‡º
   - çœŸã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’è­˜åˆ¥

4. **ã‚¯ãƒ©ã‚¹ã‚¿æŠ½å‡º**
   - Excess of Mass (EoM)
   - æœ€ã‚‚å®‰å®šã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ã‚’é¸æŠ

### ãƒã‚¤ã‚ºæ¤œå‡ºã®ä»•çµ„ã¿

```python
# ãƒ©ãƒ™ãƒ« -1 = ãƒã‚¤ã‚º
cluster_labels = clusterer.fit_predict(embeddings)

# ãƒã‚¤ã‚ºã®å®šç¾©:
# - å¯†åº¦ãŒä½ã„é ˜åŸŸã®ç‚¹
# - ã©ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã‚‚å±ã•ãªã„å­¤ç«‹ç‚¹
# - min_cluster_sizeã‚’æº€ãŸã•ãªã„å°ã‚°ãƒ«ãƒ¼ãƒ—
```

## ğŸ“ˆ æœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ

### 1. ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®èª¿æ•´

```python
# ç´°ã‹ã„ãƒãƒ£ãƒ³ã‚¯ â†’ å¤šãã®ã‚¯ãƒ©ã‚¹ã‚¿
chunk_size = 500
min_cluster_size = 10

# å¤§ãã„ãƒãƒ£ãƒ³ã‚¯ â†’ å°‘ãªã„ã‚¯ãƒ©ã‚¹ã‚¿
chunk_size = 2000
min_cluster_size = 20
```

### 2. è·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®é¸æŠ

```python
# æ„å‘³çš„åŸ‹ã‚è¾¼ã¿ã«ã¯cosineæ¨å¥¨
embeddings_model = OllamaEmbeddings(model="mxbai-embed-large")
metric = 'cosine'

# æ±ç”¨çš„ãªåŸ‹ã‚è¾¼ã¿ã«ã¯euclidean
metric = 'euclidean'
```

### 3. éšå±¤ã®æ·±ã•èª¿æ•´

```python
# æµ…ã„éšå±¤ = é€Ÿã„ã€ç²—ã„
max_depth = 1

# æ·±ã„éšå±¤ = é…ã„ã€ç´°ã‹ã„
max_depth = 3
```

## ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ»æ¤œè¨¼

### ãƒã‚¤ã‚ºçµ±è¨ˆã®ç¢ºèª

```python
raptor.index("document.txt")

# å…¨ä½“çµ±è¨ˆ
print(raptor.noise_stats['total_noise_chunks'])

# æ·±ã•åˆ¥
print(raptor.noise_stats['noise_by_depth'])
```

### Condensed Treeã®å¯è¦–åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```python
import matplotlib.pyplot as plt

# ãƒ„ãƒªãƒ¼æ§‹é€ ã‹ã‚‰clustererã‚’å–å¾—
stats = raptor.tree_structure['hdbscan_stats']
clusterer = stats['clusterer']

# å¯è¦–åŒ–
clusterer.condensed_tree_.plot(select_clusters=True)
plt.show()
```

## ğŸ’¡ ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### âœ… DO
- **ã‚³ã‚µã‚¤ãƒ³è·é›¢ã‚’ä½¿ç”¨** (æ„å‘³çš„åŸ‹ã‚è¾¼ã¿ã®å ´åˆ)
- **min_cluster_sizeã‚’æ–‡æ›¸ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹**
- **ãƒã‚¤ã‚ºçµ±è¨ˆã‚’ç¢ºèª**ã—ã¦èª¿æ•´
- **è¤‡æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿé¨“**

### âŒ DON'T
- min_cluster_sizeã‚’æ¥µç«¯ã«å°ã•ãè¨­å®šï¼ˆ<5ï¼‰
- ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„æ™‚ã«å¤§ãã„min_cluster_size
- ãƒã‚¤ã‚ºé™¤å»ãªã—ã§HDBSCANã‚’ä½¿ã†ï¼ˆæ„å‘³ãŒãªã„ï¼‰

## ğŸ†• ä»Šå¾Œã®æ‹¡å¼µæ¡ˆ

1. **Condensed treeã®æ˜ç¤ºçš„ãªæ´»ç”¨**
   ```python
   # condensed treeã‹ã‚‰ç›´æ¥éšå±¤ã‚’æŠ½å‡º
   tree = clusterer.condensed_tree_
   # ã‚«ã‚¹ã‚¿ãƒ éšå±¤ãƒãƒƒãƒ”ãƒ³ã‚°
   ```

2. **å‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**
   ```python
   # æ·±ã•ã«å¿œã˜ã¦min_cluster_sizeã‚’å¤‰æ›´
   min_cluster_size = base_size * (depth + 1)
   ```

3. **ã‚½ãƒ•ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**
   ```python
   # HDBSCANã®ç¢ºç‡çš„ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—æ´»ç”¨
   soft_clusters = hdbscan.all_points_membership_vectors(clusterer)
   ```

## ğŸ“š å‚è€ƒæ–‡çŒ®

- [HDBSCAN Documentation](https://hdbscan.readthedocs.io/)
- [RAPTOR Paper](https://arxiv.org/abs/2401.18059)
- [How HDBSCAN Works](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)

## ğŸ¤ è²¢çŒ®

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ã‚¤ã‚·ãƒ¥ãƒ¼ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ­“è¿ã—ã¾ã™ï¼

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

---

**ä½œæˆè€…:** Takato Yasuno  
**æ—¥ä»˜:** 2025å¹´10æœˆ16æ—¥
