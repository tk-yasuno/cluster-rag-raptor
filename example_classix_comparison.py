"""
RAPTOR CLASSIX vs GMM vs K-means Comparison Demo
CLASSIXã«ã‚ˆã‚‹é«˜é€Ÿã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

æ¯”è¼ƒå¯¾è±¡:
1. K-means (å›ºå®šã‚¯ãƒ©ã‚¹ã‚¿æ•°)
2. GMM + BIC (æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°è‡ªå‹•é¸æŠ)
3. CLASSIX (é«˜é€Ÿãƒ»èª¿æ•´å®¹æ˜“ãƒ»è‡ªå‹•ã‚¯ãƒ©ã‚¹ã‚¿æ•°æ±ºå®š)
"""

from langchain_ollama import ChatOllama, OllamaEmbeddings
from raptor_classix import RAPTORRetrieverCLASSIX
from raptor_gmm import RAPTORRetrieverGMM
from raptor import RAPTORRetriever
import time


def compare_clustering_methods():
    """K-meansã€GMM+BICã€CLASSIXã®æ¯”è¼ƒ"""
    
    print("=" * 80)
    print("ğŸ”¬ RAPTOR: Clustering Method Comparison")
    print("   K-means vs GMM+BIC vs CLASSIX (fast & easy tuning)")
    print("=" * 80)
    print()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    llm = ChatOllama(
        model="granite-code:8b",
        base_url="http://localhost:11434",
        temperature=0
    )
    
    embeddings_model = OllamaEmbeddings(
        model="mxbai-embed-large",
        base_url="http://localhost:11434"
    )
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_query = "philosophy"
    
    # ==========================================
    # Method 1: å¾“æ¥ã®K-meansï¼ˆå›ºå®šã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ï¼‰
    # ==========================================
    print("ğŸ“Š Method 1: K-means (Fixed cluster count = 3)")
    print("-" * 80)
    
    raptor_kmeans = RAPTORRetriever(
        embeddings_model=embeddings_model,
        llm=llm,
        max_clusters=3,
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200
    )
    
    start_time = time.time()
    raptor_kmeans.index("test.txt")
    kmeans_build_time = time.time() - start_time
    
    start_time = time.time()
    results_kmeans = raptor_kmeans.retrieve(test_query, top_k=3)
    kmeans_query_time = time.time() - start_time
    
    print(f"\nâœ… K-means Results:")
    print(f"   Build time: {kmeans_build_time:.2f}ç§’")
    print(f"   Query time: {kmeans_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_kmeans, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    print("\n")
    
    # ==========================================
    # Method 2: GMM with BICï¼ˆæœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°è‡ªå‹•é¸æŠï¼‰
    # ==========================================
    print("ğŸ“Š Method 2: GMM with BIC (Auto-optimal cluster count)")
    print("-" * 80)
    
    raptor_gmm = RAPTORRetrieverGMM(
        embeddings_model=embeddings_model,
        llm=llm,
        max_clusters=5,
        min_clusters=2,
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200,
        use_bic=True,
        clustering_method="gmm"
    )
    
    start_time = time.time()
    raptor_gmm.index("test.txt")
    gmm_build_time = time.time() - start_time
    
    start_time = time.time()
    results_gmm = raptor_gmm.retrieve(test_query, top_k=3)
    gmm_query_time = time.time() - start_time
    
    print(f"\nâœ… GMM+BIC Results:")
    print(f"   Build time: {gmm_build_time:.2f}ç§’")
    print(f"   Query time: {gmm_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_gmm, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    print("\n")
    
    # ==========================================
    # Method 3: CLASSIXï¼ˆé«˜é€Ÿãƒ»èª¿æ•´å®¹æ˜“ï¼‰
    # ==========================================
    print("ğŸ“Š Method 3: CLASSIX (Fast & Easy tuning)")
    print("-" * 80)
    
    raptor_classix = RAPTORRetrieverCLASSIX(
        embeddings_model=embeddings_model,
        llm=llm,
        radius=0.5,         # ã‚¯ãƒ©ã‚¹ã‚¿ã®åŠå¾„
        minPts=5,           # æœ€å°ãƒã‚¤ãƒ³ãƒˆæ•°
        max_depth=2,
        chunk_size=1000,
        chunk_overlap=200,
        use_cosine=True     # ã‚³ã‚µã‚¤ãƒ³è·é›¢
    )
    
    start_time = time.time()
    raptor_classix.index("test.txt")
    classix_build_time = time.time() - start_time
    
    start_time = time.time()
    results_classix = raptor_classix.retrieve(test_query, top_k=3)
    classix_query_time = time.time() - start_time
    
    print(f"\nâœ… CLASSIX Results:")
    print(f"   Build time: {classix_build_time:.2f}ç§’")
    print(f"   Query time: {classix_query_time:.3f}ç§’")
    print(f"\n   Top 3 Results:")
    for i, doc in enumerate(results_classix, 1):
        similarity = doc.metadata.get('similarity', 'N/A')
        print(f"   {i}. Similarity: {similarity}")
        print(f"      Preview: {doc.page_content[:150]}...")
    
    # CLASSIXã®çµ±è¨ˆæƒ…å ±
    print(f"\n   ğŸ“Š CLASSIX Statistics:")
    stats = raptor_classix.cluster_stats
    print(f"      Parameters: radius={stats['params']['radius']}, minPts={stats['params']['minPts']}")
    for depth in sorted(stats['total_clusters_by_depth'].keys()):
        clusters = stats['total_clusters_by_depth'][depth]
        noise = stats['noise_by_depth'].get(depth, 0)
        print(f"      Depth {depth}: {clusters} clusters, {noise} noise points")
    
    print("\n")
    
    # ==========================================
    # æ¯”è¼ƒã‚µãƒãƒªãƒ¼
    # ==========================================
    print("\n" + "=" * 80)
    print("ğŸ“Š Performance Comparison Summary")
    print("=" * 80)
    print()
    
    print("| Method               | Build Time | Query Time | Note                        |")
    print("|----------------------|------------|------------|-----------------------------|")
    print(f"| K-means (fixed)      | {kmeans_build_time:>7.2f}ç§’  | {kmeans_query_time:>7.3f}ç§’ | Manual cluster count        |")
    print(f"| GMM + BIC            | {gmm_build_time:>7.2f}ç§’  | {gmm_query_time:>7.3f}ç§’ | Auto-optimal, flexible      |")
    print(f"| CLASSIX              | {classix_build_time:>7.2f}ç§’  | {classix_query_time:>7.3f}ç§’ | Fast, easy tuning           |")
    
    print("\nğŸ¯ Key Findings:")
    print("1. CLASSIX provides fast clustering with automatic cluster count")
    print("2. Easier parameter tuning compared to HDBSCAN")
    print("3. radius parameter is intuitive (smaller = more clusters)")
    print("4. Comparable performance to GMM+BIC with less complexity")
    
    print("\nğŸ’¡ Recommendations:")
    print("â€¢ Use CLASSIX for fast prototyping and easy tuning")
    print("â€¢ Use GMM+BIC for complex, heterogeneous documents")
    print("â€¢ Use K-means when cluster structure is known")
    
    print("\nğŸ”§ CLASSIX Parameter Guide:")
    print("â€¢ radius: ã‚¯ãƒ©ã‚¹ã‚¿ã®åŠå¾„ (å°ã•ã„ã»ã©ç´°ã‹ãåˆ†å‰²)")
    print("  - Small docs (100-500 chars): 0.3-0.4")
    print("  - Medium docs (500-1500 chars): 0.4-0.6")
    print("  - Large docs (1500+ chars): 0.5-0.8")
    print("â€¢ minPts: æœ€å°ãƒã‚¤ãƒ³ãƒˆæ•° (3-10æ¨å¥¨)")
    print("  - Small datasets: 3-5")
    print("  - Large datasets: 5-10")
    
    print("\n" + "=" * 80)


def test_different_parameters():
    """CLASSIXã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“"""
    
    print("\n" + "=" * 80)
    print("ğŸ§ª CLASSIX Parameter Tuning Experiment")
    print("=" * 80)
    print()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    llm = ChatOllama(
        model="granite-code:8b",
        base_url="http://localhost:11434",
        temperature=0
    )
    
    embeddings_model = OllamaEmbeddings(
        model="mxbai-embed-large",
        base_url="http://localhost:11434"
    )
    
    test_query = "philosophy"
    
    # ç•°ãªã‚‹radiusã§ãƒ†ã‚¹ãƒˆ
    radius_values = [0.3, 0.4, 0.5, 0.6]
    
    results_summary = []
    
    for radius in radius_values:
        print(f"\n{'='*80}")
        print(f"Testing radius = {radius}")
        print(f"{'='*80}")
        
        raptor = RAPTORRetrieverCLASSIX(
            embeddings_model=embeddings_model,
            llm=llm,
            radius=radius,
            minPts=5,
            max_depth=2,
            chunk_size=1000,
            chunk_overlap=200,
            use_cosine=True
        )
        
        start_time = time.time()
        raptor.index("test.txt")
        build_time = time.time() - start_time
        
        results = raptor.retrieve(test_query, top_k=3)
        
        # çµ±è¨ˆã‚’é›†è¨ˆ
        total_clusters = sum(raptor.cluster_stats['total_clusters_by_depth'].values())
        total_noise = sum(raptor.cluster_stats['noise_by_depth'].values())
        
        results_summary.append({
            'radius': radius,
            'build_time': build_time,
            'total_clusters': total_clusters,
            'total_noise': total_noise,
            'top_similarity': results[0].metadata.get('similarity', 'N/A') if results else 'N/A'
        })
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ“Š Parameter Tuning Summary")
    print("=" * 80)
    print()
    print("| radius | Build Time | Total Clusters | Total Noise | Top Similarity |")
    print("|--------|------------|----------------|-------------|----------------|")
    for res in results_summary:
        print(f"| {res['radius']:>6.1f} | {res['build_time']:>7.2f}ç§’  | {res['total_clusters']:>14} | {res['total_noise']:>11} | {res['top_similarity']:>14} |")
    
    print("\nğŸ’¡ Observations:")
    print("â€¢ Smaller radius â†’ More clusters, finer granularity")
    print("â€¢ Larger radius â†’ Fewer clusters, coarser grouping")
    print("â€¢ Optimal radius depends on document characteristics")
    print("=" * 80)


if __name__ == "__main__":
    # ãƒ¡ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“
    compare_clustering_methods()
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # test_different_parameters()
