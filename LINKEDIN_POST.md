# LinkedIn投稿案

## バージョン1: 技術者向け（詳細版）

```
🌳 RAPTOR: 階層的RAGシステムのオープンソース実装を公開しました

大規模文書検索の課題に取り組み、O(log n)の検索アルゴリズムを完全実装しました。

📊 実証結果:
• 1.83M文字（764ページ）の機械学習教科書で検証
• 文書量26倍でもクエリ時間は一定（約2秒）
• 100%ローカルLLM（Ollama + Granite Code 8B）

🔬 主な特徴:
• 階層的クラスタリングによるツリー構造
• K-meansとLLM要約の組み合わせ
• 5つの実用例（Wikipedia～技術文書）

💡 実務適用例:
• 技術文書の統合検索システム
• 企業内マニュアルのQAシステム
• 研究論文データベースのナビゲーション

GitHub: https://github.com/tk-yasuno/cluster-rag-raptor

LangChain, RAG, 自然言語処理に興味のある方との繋がりを楽しみにしています。

#MachineLearning #NLP #RAG #LangChain #OpenSource #AI #Python #InformationRetrieval
```

---

## バージョン2: ビジネス向け（簡潔版）

```
🚀 大規模文書検索を効率化する新しいアプローチ

180万文字の文書を2秒で検索できる階層的RAGシステムを開発し、オープンソースとして公開しました。

従来の検索手法（O(n)）に対して、階層的ツリー構造により検索時間をO(log n)に削減。
文書量が26倍になっても検索速度はほぼ一定を実証。

✅ 100%オープンソース
✅ ローカル実行可能（Ollama使用）
✅ 実務適用可能な5つの事例

企業の技術文書検索、社内マニュアルのQA、研究データベースなど、
大量の文書を扱う業務での活用を想定しています。

https://github.com/tk-yasuno/cluster-rag-raptor

#AI #MachineLearning #NLP #Innovation #OpenSource
```

---

## バージョン3: 超簡潔版（1分で読める）

```
📚 大規模文書検索の課題を解決するオープンソースを公開

RAPTOR: 階層的RAGシステム
• 180万文字を2秒で検索
• 文書量に依存しない一定速度（O(log n)を実証）
• 100%ローカル実行可能

5つの実用例つき（Wikipedia、学術論文、技術文書など）

https://github.com/tk-yasuno/cluster-rag-raptor

#AI #MachineLearning #OpenSource
```

---

## バージョン4: ストーリー形式（エンゲージメント重視）

```
💡 大規模文書検索の「速度の壁」をどう超えるか？

LangChainの学習中、ColBERTがWindows環境で動作しない問題に直面しました。

そこで、RAPTOR（階層的RAG）を完全実装し、
さらに5つの異なるスケールで検証を行いました。

📈 検証結果:
• 70KB → 1.83MB（26倍のスケール）
• クエリ時間: 2.5秒 → 2.0秒（むしろ高速化）

これはO(log n)アルゴリズムの理論的優位性が、
実務レベルで証明された瞬間でした。

🎯 学んだこと:
1. パラメータの段階的最適化の重要性
2. chunk_size=1500が100万文字超に最適
3. 構築時間47分でも、1400回以上使えばROI+

すべてをオープンソースとして公開しています。
https://github.com/tk-yasuno/cluster-rag-raptor

同じような課題に取り組んでいる方、
フィードバックをいただけると嬉しいです！

#MachineLearning #AI #OpenSource #LangChain #RAG #NLP
```

---

## 投稿のコツ

### タイミング

- **平日**: 火〜木曜日
- **時間**: 8:00-9:00 または 12:00-13:00（昼休み）

### エンゲージメントを高めるポイント

1. **最初の2行が重要**: LinkedInは省略表示されるため
2. **絵文字を適度に使用**: 🌳 📊 🚀 など
3. **具体的な数値**: 1.83M文字、2秒、26倍など
4. **Call to Action**: 「フィードバックをお願いします」など

### ハッシュタグ戦略

- **3-5個が最適** (多すぎるとスパムっぽい)
- **人気タグ**: #MachineLearning #AI #OpenSource
- **ニッチタグ**: #LangChain #RAG #NLP

### フォローアップコメント

投稿後、自分でコメントを追加すると良い:

```
技術的な詳細について:
- LLM: Granite Code 8B (8Bパラメータ)
- Embeddings: mxbai-embed-large (1024次元)
- クラスタリング: K-means
- 深さ: 3階層まで対応

質問があればお気軽にどうぞ！
```

---

## 推奨投稿バージョン

**プロフェッショナル向け**: バージョン4（ストーリー形式）

- エンゲージメントが最も高い
- 技術的詳細とビジネス価値のバランスが良い
- 「学び」を共有する形で共感を得やすい

**時間がない場合**: バージョン3（超簡潔版）

- 1分で読める
- 重要な情報は全て含まれている
- ハッシュタグで発見されやすい
